{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastAI\n",
    "> FastAI致力于简化深度学习任务的流程，使得从数据预处理到模型训练和部署都变得更加容易和快速。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本用法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[官方文档](https://docs.fast.ai/quick_start.html)\n",
    "\n",
    "FastAI 是一个深度学习库，它为从业者提供高级组件，这些组件可以在标准深度学习领域快速轻松地使用\n",
    "\n",
    "Fastai 提供了对四种数据的深度学习，分别是图像、文本、协同过滤、表格，导入方式分别是\n",
    "```\n",
    "from fastai.vision.all import *\n",
    "from fastai.text.all import *\n",
    "from fastai.collab import *\n",
    "from fastai.tabular.all import *\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [Path('/Users/hawkins/.fastai/data/adult_sample/adult.csv'),Path('/Users/hawkins/.fastai/data/adult_sample/export.pkl'),Path('/Users/hawkins/.fastai/data/adult_sample/models')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.ADULT_SAMPLE)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>Private</td>\n",
       "      <td>101320</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>1902</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>236746</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>10520</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>96185</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>112847</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>82297</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt     education  education-num  \\\n",
       "0   49            Private  101320    Assoc-acdm           12.0   \n",
       "1   44            Private  236746       Masters           14.0   \n",
       "2   38            Private   96185       HS-grad            NaN   \n",
       "3   38       Self-emp-inc  112847   Prof-school           15.0   \n",
       "4   42   Self-emp-not-inc   82297       7th-8th            NaN   \n",
       "\n",
       "        marital-status        occupation    relationship                 race  \\\n",
       "0   Married-civ-spouse               NaN            Wife                White   \n",
       "1             Divorced   Exec-managerial   Not-in-family                White   \n",
       "2             Divorced               NaN       Unmarried                Black   \n",
       "3   Married-civ-spouse    Prof-specialty         Husband   Asian-Pac-Islander   \n",
       "4   Married-civ-spouse     Other-service            Wife                Black   \n",
       "\n",
       "       sex  capital-gain  capital-loss  hours-per-week  native-country salary  \n",
       "0   Female             0          1902              40   United-States  >=50k  \n",
       "1     Male         10520             0              45   United-States  >=50k  \n",
       "2   Female             0             0              32   United-States   <50k  \n",
       "3     Male             0             0              40   United-States  >=50k  \n",
       "4   Female             0             0              50   United-States   <50k  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'adult.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hawkins/miniconda3/envs/ai/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "dls = TabularDataLoaders.from_csv(path/'adult.csv', path=path, y_names=\"salary\",\n",
    "    cat_names = ['workclass', 'education', 'marital-status', 'occupation',\n",
    "                 'relationship', 'race'],\n",
    "    cont_names = ['age', 'fnlwgt', 'education-num'],\n",
    "    procs = [Categorify, FillMissing, Normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>education-num_na</th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>False</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>117477.001358</td>\n",
       "      <td>9.0</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>False</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>165235.000239</td>\n",
       "      <td>13.0</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>269094.997908</td>\n",
       "      <td>13.0</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>116631.998695</td>\n",
       "      <td>16.0</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>False</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>325706.003095</td>\n",
       "      <td>15.0</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>373184.999471</td>\n",
       "      <td>10.0</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>19.000001</td>\n",
       "      <td>318821.995249</td>\n",
       "      <td>9.0</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>False</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>179186.000090</td>\n",
       "      <td>13.0</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>340458.001822</td>\n",
       "      <td>9.0</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>155488.998496</td>\n",
       "      <td>10.0</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.367530</td>\n",
       "      <td>0.350070</td>\n",
       "      <td>0.832924</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.364322</td>\n",
       "      <td>0.342810</td>\n",
       "      <td>0.842291</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = tabular_learner(dls, metrics=accuracy)\n",
    "learn.fit_one_cycle(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0: 0.1516208052635193\n",
      "Label 1: 0.0752926617860794\n",
      "Label 2: 0.041321493685245514\n",
      "Label 3: 0.4554940164089203\n",
      "Label 4: 0.27627110481262207\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 模型的输出\n",
    "output = torch.tensor([1.2, 0.5, -0.1, 2.3, 1.8])\n",
    "\n",
    "# 计算对数概率\n",
    "log_probs = F.log_softmax(output, dim=0)\n",
    "\n",
    "# 打印每个标签的概率\n",
    "for i, log_prob in enumerate(log_probs):\n",
    "    print(f\"Label {i}: {torch.exp(log_prob)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-9.7319)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "\n",
    "# 重新排列维度\n",
    "y = x.permute(1, 0)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "lstm = nn.LSTM(12, 128, batch_first=True, num_layers=1) # 输入\n",
    "output, (hn, cn) = lstm(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 128]), torch.Size([1, 128]), torch.Size([1, 128]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape, hn.shape, cn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Parameter containing:\n",
       "  tensor([[-0.2712,  0.0327,  0.4179],\n",
       "          [-0.4061,  0.2711,  0.3709],\n",
       "          [ 0.5648, -0.4041,  0.1398],\n",
       "          [-0.4269,  0.4929, -0.2240],\n",
       "          [ 0.3478,  0.0172, -0.0450],\n",
       "          [-0.0184,  0.0981,  0.2722],\n",
       "          [ 0.0926,  0.1761, -0.5193],\n",
       "          [ 0.4206,  0.5034,  0.4772],\n",
       "          [ 0.4268, -0.4166, -0.2140],\n",
       "          [ 0.5091, -0.4397,  0.5238],\n",
       "          [-0.4541, -0.4067,  0.2823],\n",
       "          [-0.4148, -0.1323,  0.4200]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.4573,  0.5460, -0.1172],\n",
       "          [-0.4488,  0.5685, -0.1230],\n",
       "          [-0.2375,  0.1407, -0.4038],\n",
       "          [ 0.3795,  0.3618, -0.4581],\n",
       "          [-0.4742, -0.0506,  0.2425],\n",
       "          [-0.0167, -0.2928,  0.0132],\n",
       "          [-0.5427, -0.4080, -0.3843],\n",
       "          [ 0.4755,  0.5089, -0.1961],\n",
       "          [ 0.0259,  0.2575,  0.0692],\n",
       "          [-0.2891,  0.3330,  0.3549],\n",
       "          [-0.0335, -0.0711,  0.5247],\n",
       "          [ 0.5047, -0.3273,  0.5649]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1429, -0.3835,  0.3160, -0.4310,  0.5334, -0.3712,  0.1633,  0.1758,\n",
       "           0.1373,  0.4789, -0.2398, -0.2437], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.5003, -0.0237, -0.2735,  0.0231, -0.1184,  0.1916,  0.4995,  0.1704,\n",
       "          -0.1860, -0.2833, -0.5035,  0.4858], requires_grad=True)]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = nn.LSTM(3, 3)\n",
    "lstm.all_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 3])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [torch.randn(1,3) for _ in range(5)]\n",
    "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化隐藏状态\n",
    "hidden = (torch.randn(1, 1, 3),\n",
    "          torch.randn(1, 1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[1], inputs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.6706, -0.4929,  1.5050]]]), torch.Size([1, 1, 3]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[1].view(1, 1, -1), inputs[1].view(1, 1, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in inputs:\n",
    "     out, hidden = lstm(i.view(1, 1, -1), hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1575,  0.0259, -0.0575]]], grad_fn=<MkldnnRnnLayerBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size = 3\n",
    "total = 15\n",
    "batch_size = 5\n",
    "\n",
    "inputs = [torch.randn(1,feature_size) for _ in range(total)]\n",
    "\n",
    "\n",
    "def get_batch_iter():\n",
    "    for i in range(0, total, batch_size):\n",
    "        yield torch.cat(inputs[i:min(i+batch_size, total)])\n",
    "\n",
    "batch_iter = get_batch_iter()\n",
    "x = next(batch_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3]), 5)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, x.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型\n",
    "class torch.nn.LSTM(*args, **kwargs)\n",
    "\n",
    "参数列表\n",
    "\n",
    "- input_size：x的特征维度\n",
    "- hidden_size：隐藏层的特征维度\n",
    "- num_layers：lstm隐层的层数，默认为1\n",
    "- bias：False则bih=0和bhh=0. 默认为True\n",
    "- batch_first：True则输入输出的数据格式为 (batch, seq, feature)\n",
    "- dropout：除最后一层，每一层的输出都进行dropout，默认为: 0\n",
    "- bidirectional：True则为双向lstm默认为False\n",
    "- 输入：input, (h0, c0)\n",
    "- 输出：output, (hn,cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = feature_size\n",
    "num_layers = 1\n",
    "hidden_size = 3\n",
    "\n",
    "lstm = nn.LSTM(input_size, hidden_size, batch_first=True, num_layers=num_layers) # 输入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入：input, (h0, c0)\n",
    "# 输入数据格式：\n",
    "# input(batch, seq_len, input_size)\n",
    "# h0(num_layers * num_directions, batch, hidden_size)\n",
    "# c0(num_layers * num_directions, batch, hidden_size)\n",
    "# num_directions 代表lstm的方向数，其实就是是否为双向lstm。如果你用的网络是双向（bidirectional==True）则num_directions’为2，如果不是，则为1\n",
    "\n",
    "h0 = torch.zeros(num_layers, x.size(0), hidden_size)\n",
    "c0 = torch.zeros(num_layers, x.size(0), hidden_size)\n",
    "hidden = (h0, c0)  \n",
    "\n",
    "\n",
    "# LSTM 返回的第一个值表示所有时刻的隐状态值, 第二个值表示最近的隐状态值 (因此下面的 \"out\"的最后一个值和 \"hidden\" 的值是一样的).\n",
    "# 之所以这样设计, 是为了通过 \"out\" 的值来获取所有的隐状态值, 而用 \"hidden\" 的值来\n",
    "# 进行序列的反向传播运算, 具体方式就是将它作为参数传入后面的 LSTM 网络.\n",
    "out, (hn, cn) = lstm(x, hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **注意：input 的batch 必须和hidden的batch，也就是第二个参数相同！** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 1, 3]), torch.Size([1, 5, 3]), torch.Size([1, 5, 3]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输出数据格式：\n",
    "# output(batch, seq_len,  hidden_size * num_directions)\n",
    "# hn(num_layers * num_directions, batch, hidden_size)\n",
    "# cn(num_layers * num_directions, batch, hidden_size)\n",
    "\n",
    "out.shape, hn.shape, cn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-8.5360e-02, -4.1744e-03, -1.4452e-01]],\n",
       " \n",
       "         [[-8.6979e-05, -9.0539e-02,  1.4557e-01]],\n",
       " \n",
       "         [[-8.8682e-02,  9.1704e-02, -1.1052e-01]],\n",
       " \n",
       "         [[-1.2795e-01,  8.7705e-02, -1.8030e-01]],\n",
       " \n",
       "         [[ 2.3082e-01, -1.1413e-01,  8.8840e-02]]],\n",
       "        grad_fn=<TransposeBackward0>),\n",
       " (tensor([[[-8.5360e-02, -4.1744e-03, -1.4452e-01],\n",
       "           [-8.6979e-05, -9.0539e-02,  1.4557e-01],\n",
       "           [-8.8682e-02,  9.1704e-02, -1.1052e-01],\n",
       "           [-1.2795e-01,  8.7705e-02, -1.8030e-01],\n",
       "           [ 2.3082e-01, -1.1413e-01,  8.8840e-02]]], grad_fn=<StackBackward0>),\n",
       "  tensor([[[-1.8463e-01, -6.7775e-03, -3.8707e-01],\n",
       "           [-2.8391e-04, -1.1626e-01,  3.0000e-01],\n",
       "           [-1.9160e-01,  1.3820e-01, -2.7486e-01],\n",
       "           [-3.2372e-01,  1.3617e-01, -6.0256e-01],\n",
       "           [ 3.8518e-01, -2.5076e-01,  1.8670e-01]]], grad_fn=<StackBackward0>)))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out, (hn, cn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(Module):\n",
    "    \"Basic model for tabular data.\"\n",
    "    def __init__(self, \n",
    "        emb_szs:list, # Sequence of (num_embeddings, embedding_dim) for each categorical variable\n",
    "        n_cont:int, # Number of continuous variables\n",
    "        out_sz:int, # Number of outputs for final `LinBnDrop` layer\n",
    "        layers:list, # Sequence of ints used to specify the input and output size of each `LinBnDrop` layer\n",
    "        ps:float|MutableSequence=None, # Sequence of dropout probabilities for `LinBnDrop`\n",
    "        embed_p:float=0., # Dropout probability for `Embedding` layer\n",
    "        y_range=None, # Low and high for `SigmoidRange` activation \n",
    "        use_bn:bool=True, # Use `BatchNorm1d` in `LinBnDrop` layers\n",
    "        bn_final:bool=False, # Use `BatchNorm1d` on final layer\n",
    "        bn_cont:bool=True, # Use `BatchNorm1d` on continuous variables\n",
    "        act_cls=nn.ReLU(inplace=True), # Activation type for `LinBnDrop` layers\n",
    "        n_lstm=1,\n",
    "        lin_first:bool=True # Linear layer is first or last in `LinBnDrop` layers\n",
    "    ):\n",
    "        ps = ifnone(ps, [0]*len(layers))\n",
    "        if not is_listy(ps): ps = [ps]*len(layers)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont) if bn_cont else None\n",
    "        self.n_cont = n_cont\n",
    "        sizes = [n_cont] + layers + [out_sz]\n",
    "        actns = [act_cls for _ in range(len(sizes)-2)] + [None]\n",
    "        _layers = [LinBnDrop(sizes[i], sizes[i+1], bn=use_bn and (i!=len(actns)-1 or bn_final), p=p, act=a, lin_first=lin_first)\n",
    "                       for i,(p,a) in enumerate(zip(ps+[0.],actns))]\n",
    "        if y_range is not None: _layers.append(SigmoidRange(*y_range))\n",
    "        self.layers = nn.Sequential(*_layers)\n",
    "        self.lstm = nn.LSTM(n_cont, 64, batch_first=True, num_layers=1)\n",
    "\n",
    "    def forward(self, x_cat, x_cont=None):\n",
    "        x_lstm, _ = self.lstm(x_cont)\n",
    "        x_lstm = x_lstm[-1, :]\n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        x = torch.cat([x_cont, x_lstm], 1)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitter = EndSplitter(valid_pct=0.2, valid_last=True)(range_of(train_all))\n",
    "splitter = RandomSplitter(valid_pct=0.2)(range_of(train_all))\n",
    "\n",
    "to = TabularPandas(train_all, procs=[FillMissing,Normalize],\n",
    "                   cont_names = features,\n",
    "                   y_block = CategoryBlock,\n",
    "                   y_names='awake',\n",
    "                   splits=splitter, \n",
    "                   device=def_device) # Important: Specify training on GPU \n",
    "\n",
    "dls = to.dataloaders(bs=12*60*24, num_workers=4) # Important: use multiple threads.\n",
    "\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event(df):\n",
    "    lstCV = zip(df.series_id, df.smooth)\n",
    "    lstPOI = []\n",
    "    for (c, v), g in groupby(lstCV, lambda cv: (cv[0], cv[1] != 0 and not pd.isnull(cv[1]))):\n",
    "        llg = sum(1 for item in g)\n",
    "        print(c,v,llg)\n",
    "        if v is False:\n",
    "            lstPOI.extend([0] * llg)\n",
    "        else:\n",
    "            lstPOI.extend(['onset'] + (llg - 2) * [0] + ['wakeup'] if llg > 1 else [0])\n",
    "    return lstPOI\n",
    "\n",
    "test_p[\"event\"] = get_event(test_p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
